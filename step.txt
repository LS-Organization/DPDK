# 1) veth
sudo ip link del veth0 2>/dev/null || true
sudo ip link add veth0 type veth peer name veth1
sudo ip link set veth0 up
sudo ip link set veth1 up
sudo ip addr add 10.10.0.1/24 dev veth0 2>/dev/null || true
sudo ip addr add 10.10.0.2/24 dev veth1 2>/dev/null || true

# 2) 启动（建议加 --no-pci，避免物理 ENA 抢占端口 0）
sudo ./dpdk_echo -l 0 -n 4 --no-pci --vdev='net_af_packet0,iface=veth0'
# 启动日志里应显示：driver=net_af_packet；随后进入 Echo loop

# 3) 发包（从 veth1）
sudo python3 - <<'PY'
from scapy.all import *
sendp(Ether(dst="ff:ff:ff:ff:ff:ff")/
      IP(src="10.10.0.2", dst="10.10.0.3")/
      UDP(sport=12345, dport=9000)/Raw(b"hello-afp"),
      iface="veth1", count=5)
PY

# 可抓回包：
sudo tcpdump -n -i veth1 udp and port 9000 -c 5




########################################################


In AWS EC2, the virtual NIC is ENA, which is a PCI device.
However:

AWS does not allow direct access to raw Ethernet (Layer 2) frames.

The DPDK net_ena driver works only at the PCI level, not at raw Ethernet level.

Packets sent through veth or Linux sockets never reach the ENA RX/TX queues.

So previously:

Your DPDK program was polling ENA (port 0, a PCI device),
while your Scapy packets were injected into veth.
They lived in completely different worlds — hence, no packets were ever received.

################################################################################

Fix #1: --no-pci + net_af_packet

Originally, you ran:

sudo ./dpdk_echo -l 0 -n 4 --vdev='net_af_packet0,iface=veth0'


By default, DPDK enumerates all PCI devices first,
so port 0 was your ENA interface, and net_af_packet0 became port 1.

Your code hardcoded port 0 → so it was polling ENA (wrong interface).


By adding:

--no-pci


you told DPDK to skip PCI device discovery entirely.
Now the only interface is net_af_packet0, which becomes port 0.

→ The DPDK app finally polls the correct interface (veth0) and receives packets from Scapy.

#########################################################################################

Fix #2: Automatic vdev port selection (no more hardcoded port 0)

We also improved the code to automatically detect and select the correct DPDK port:

for (uint16_t p = 0; p < nports; ++p) {
    rte_eth_dev_info_get(p, &info);
    if (strstr(info.driver_name, "net_af_packet")) {
        selected = p;
        break;
    }
}


Now the program:

Scans all available DPDK ports

Finds one whose driver name includes "net_af_packet"

Automatically uses that port for RX/TX

So even if you remove --no-pci, it will still ignore the ENA interface and use the virtual AF_PACKET one correctly.

#########################################################################

Fix #3: Using veth as a real L2 bridge

You created a virtual Ethernet pair:

sudo ip link add veth0 type veth peer name veth1
sudo ip link set veth0 up
sudo ip link set veth1 up


This creates a virtual Ethernet cable inside Linux —
veth0 and veth1 are directly connected at Layer 2.

DPDK uses net_af_packet bound to veth0

Scapy sends packets via veth1

Both can exchange real Ethernet frames

So this setup effectively emulates a real NIC + wire on a single AWS instance.